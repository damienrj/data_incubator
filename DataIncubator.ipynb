{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odds of being more than 3 locations away after 10 steps\n",
      "0.5400000000\n",
      "odds of being more than 10 locations away after 60 steps\n",
      "0.2700000000\n",
      "Odds of ever being more than 5 locations away after 10 steps\n",
      "0.1400000000\n",
      "Odds of ever being more than 10 locations away after 60 steps\n",
      "0.3700000000\n",
      "Odds of being more than one block east of orgin, and finishing more than one block west\n",
      "10 Steps\n",
      "0.0200000000\n",
      "60 Steps\n",
      "0.3600000000\n",
      "Steps to go 10\n",
      "104.9500000000\n",
      "Steps to go 60\n",
      "3802.0200000000\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "#Question 1\n",
    "#Random motion \n",
    "class Location():\n",
    "    \n",
    "    def __init__(self, x, y):\n",
    "        \"\"\"x and y are floats\"\"\"\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def move(self, deltaX, deltaY):\n",
    "        \"\"\"deltaX and deltaY are floats\"\"\"\n",
    "        return Location(self.x + deltaX, self.y + deltaY)\n",
    "       \n",
    "    def distFrom(self, other):\n",
    "        xDist = self.x - other.x\n",
    "        yDist = self.y - other.y\n",
    "        return (xDist**2 + yDist**2)**0.5\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '<' + str(self.x) + ', ' + str(self.y) + '>'\n",
    "\n",
    "class City():\n",
    "    #Possible to add multiple tourists\n",
    "    def __init__(self):\n",
    "        self.tourists = {}\n",
    "            \n",
    "    def moveTourist(self, tourist):\n",
    "        #Makes tourist take step and then update location\n",
    "        xDist, yDist = tourist.takeStep()\n",
    "        currentLocation = self.tourists[tourist]\n",
    "        \n",
    "        #Use Location's move method\n",
    "        self.tourists[tourist] = currentLocation.move(xDist, yDist)\n",
    "      \n",
    "\n",
    "class Tourist():\n",
    "\n",
    "    def takeStep(self):\n",
    "        #The possible options are north, south, east and west.\n",
    "        #(x, y) -> (0,1) is North, (1, 0) East, etc.\n",
    "        stepChoices = [(0.0,1.0), (0.0,-1.0), (1.0, 0.0), (-1.0, 0.0)]\n",
    "        return random.choice(stepChoices)\n",
    "\n",
    "\n",
    "\n",
    "def walk(city, tourist, numSteps, travel_range=None):\n",
    "    #Gets location of tourist in city\n",
    "    start = city.tourists[tourist]\n",
    "    max_distance=0\n",
    "    east=0\n",
    "    west=0\n",
    "    east_west=0\n",
    "    last_step=0\n",
    "    \n",
    "    for s in range(numSteps):\n",
    "        #Moves tourist multiple times\n",
    "        city.moveTourist(tourist)\n",
    "        current_distance = start.distFrom(city.tourists[tourist])\n",
    "        #Check for max distance\n",
    "        if current_distance > max_distance:\n",
    "            max_distance = current_distance\n",
    "        #Check if present on E and W side\n",
    "        if city.tourists[tourist].x > 1:\n",
    "            east=1\n",
    "        if city.tourists[tourist].x < -1:\n",
    "            west=1\n",
    "        if east and west:\n",
    "            east_west=1\n",
    "        \n",
    "        #Check if travel_range reached\n",
    "        if current_distance >= travel_range and travel_range is not None:\n",
    "            last_step=s+1\n",
    "            break\n",
    "    return((current_distance, max_distance, east_west, last_step))\n",
    "\n",
    "\n",
    "\n",
    "def simWalks(numSteps, numTrials, travel_range=None):\n",
    "    \n",
    "    bob = Tourist()\n",
    "    origin = Location(0, 0)\n",
    "    distances = []\n",
    "    max_distances = []\n",
    "    both_sides = []\n",
    "    last_steps = []\n",
    "    for t in range(numTrials):\n",
    "        Grandeville = City()\n",
    "        Grandeville.tourists[bob]= origin\n",
    "        result = walk(Grandeville, bob, numSteps, travel_range)\n",
    "        distances.append(result[0])\n",
    "        max_distances.append(result[1])\n",
    "        both_sides.append(result[2])\n",
    "        last_steps.append(result[3])\n",
    "    return (distances, max_distances, both_sides, last_steps)\n",
    "\n",
    "\n",
    "sim_num=100\n",
    "#odds of being more than 3 locations away after 10 steps\n",
    "random.seed(0)\n",
    "steps=10\n",
    "data = pd.DataFrame(simWalks(steps, sim_num)[0], columns=['Distance'])\n",
    "print('odds of being more than 3 locations away after 10 steps')\n",
    "print('{0:.10f}'.format(sum(data.Distance>3)/float(data.shape[0])))\n",
    "\n",
    "#odds of being more than 10 locations away after 60 steps\n",
    "random.seed(0)\n",
    "steps=60\n",
    "data = pd.DataFrame(simWalks(steps, sim_num)[0], columns=['Distance'])\n",
    "print('odds of being more than 10 locations away after 60 steps')\n",
    "print('{0:.10f}'.format(sum(data.Distance>10)/float(data.shape[0])))\n",
    "\n",
    "#odds of ever being more than 5 locations away after 10 steps\n",
    "random.seed(0)\n",
    "steps=10\n",
    "data = simWalks(steps, sim_num)\n",
    "data = pd.DataFrame({'Distance': data[0],'Max_Distance': data[1] })\n",
    "print('Odds of ever being more than 5 locations away after 10 steps')\n",
    "print('{0:.10f}'.format(sum(data.Max_Distance>5)/float(data.shape[0])))\n",
    "\n",
    "#Odds of ever being more than 10 locations away after 60 steps\n",
    "random.seed(0)\n",
    "steps=60\n",
    "data = simWalks(steps, sim_num)\n",
    "data = pd.DataFrame({'Distance': data[0],'Max_Distance': data[1] })\n",
    "print('Odds of ever being more than 10 locations away after 60 steps')\n",
    "print('{0:.10f}'.format(sum(data.Max_Distance>10)/float(data.shape[0])))\n",
    "\n",
    "#Odds of being more than one block east of orgin, and finishing more than one block west\n",
    "random.seed(0)\n",
    "steps=10\n",
    "data = simWalks(steps, sim_num)\n",
    "data = pd.DataFrame({'Distance': data[0],'Max_Distance': data[1],'Both': data[2] })\n",
    "print('Odds of being more than one block east of orgin, and finishing more than one block west')\n",
    "print('10 Steps')\n",
    "print('{0:.10f}'.format(sum(data.Both)/float(data.shape[0])))\n",
    "\n",
    "steps=60\n",
    "data = simWalks(steps, sim_num)\n",
    "data = pd.DataFrame({'Distance': data[0],'Max_Distance': data[1],'Both': data[2] })\n",
    "print('60 Steps')\n",
    "print('{0:.10f}'.format(sum(data.Both)/float(data.shape[0])))\n",
    "\n",
    "#Number of steps required to go a desired distance\n",
    "random.seed(0)\n",
    "steps=10000000\n",
    "travel_range = 10\n",
    "data = simWalks(steps, sim_num, travel_range)\n",
    "data = pd.DataFrame({'Distance': data[0],'Max_Distance': data[1],'Both': data[2], 'Last' : data[3] })\n",
    "print('Steps to go 10')\n",
    "print('{0:.10f}'.format(data.Last.mean()))\n",
    "\n",
    "random.seed(0)\n",
    "steps=10000000\n",
    "travel_range = 60\n",
    "data = simWalks(steps, sim_num, travel_range)\n",
    "data = pd.DataFrame({'Distance': data[0],'Max_Distance': data[1],'Both': data[2], 'Last' : data[3] })\n",
    "print('Steps to go 60')\n",
    "print('{0:.10f}'.format(data.Last.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio of complaints to second largest agency\n",
      "0.1719314121\n",
      "the largest ratio of the conditional probability of a complaint type given a specified borough divided by the unconditioned probability of that complaint type\n",
      "1.83649665535\n",
      "The distance (in degrees) between the 90% and 10% percentiles of degrees latitude\n",
      "0.2357908310\n",
      "356.5738542531square km\n",
      "Call Number Difference\n",
      "500063.0000000000\n",
      "standard deviation of time between calls\n",
      "56.6804736870\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "data_sub = pd.read_csv('nyc311calls.csv.gz', usecols=['Agency', 'Agency Name', 'Borough','Latitude', 'Longitude', 'Complaint Type',  ])\n",
    "agency=data_sub.groupby('Agency')\n",
    "#Ratio of complaints to second largest agency\n",
    "#(by complaint volume) divided by total number of complaints\n",
    "answer = agency.size().sort_values(ascending =False)[1]/data_sub.shape[0]\n",
    "print('Ratio of complaints to second largest agency')\n",
    "print('{0:.10f}'.format(answer))\n",
    "\n",
    "boroughs = data_sub.groupby(['Borough', 'Complaint Type'] )\n",
    "complaints = boroughs.size()\n",
    "\n",
    "#Odds of complaint type within borough\n",
    "prob_complaint_B = complaints / complaints.sum(level=0)\n",
    "#Odds of complaint type in general\n",
    "prob_complaint = complaints/complaints.sum(level=1)\n",
    "\n",
    "print(\"\"\"the largest ratio of the conditional probability of a complaint type given a specified borough divided by the unconditioned probability of that complaint type\"\"\")\n",
    "print((prob_complaint_B / prob_complaint).sort_values(ascending =False)[0])\n",
    "\n",
    "print(\"\"\"The distance (in degrees) between the 90% and 10% percentiles of degrees latitude\"\"\")\n",
    "print('{0:.10f}'.format(data_sub.Latitude.quantile(.90)-data_sub.Latitude.quantile(.10)))\n",
    "\n",
    "#Calculate area servered by 311 (How many square kilometers is the single-standard-deviation ellipse)\n",
    "#Remove entries with missing gps data\n",
    "x = data_sub.Latitude\n",
    "x = x[x.isnull()==False]\n",
    "y = data_sub.Longitude\n",
    "y = y[y.isnull()==False]\n",
    "\n",
    "#Find the ellipse angle, and then use Area = pi*stdx*stdy\n",
    "dx2 = sum((x-np.mean(x))**2)\n",
    "dy2 = sum((y-np.mean(y))**2)\n",
    "A = dx2 - dy2\n",
    "B = np.sqrt(A**2 + 4 * sum((x-np.mean(x))*(y-np.mean(y)))**2)\n",
    "C = 2*sum((x-np.mean(x))*(y-np.mean(y)))\n",
    "theta = np.arctan( (A+B)/C )\n",
    "n = len(x)\n",
    "Sx = np.sqrt(2* sum(((x-np.mean(x))*np.cos(theta) - (y-np.mean(y))*np.sin(theta))**2) / n)\n",
    "Sy = np.sqrt(2* sum(((x-np.mean(x))*np.sin(theta) - (y-np.mean(y))*np.cos(theta))**2) / n)\n",
    "\n",
    "#12365.1613 square km per degree\n",
    "print('{0:.10f}'.format(np.pi*Sx*Sy*12365.1613) + ' square km')\n",
    "\n",
    "\n",
    "#Find the difference between most calls in an hour and least in an hour\n",
    "#Call Data\n",
    "data_calls = pd.read_csv('nyc311calls.csv.gz', usecols=['Agency', 'Agency Name', 'Borough','Latitude', 'Longitude', 'Complaint Type', 'Created Date', 'Status' ])\n",
    "data_calls['Created Date'] = pd.to_datetime(data_calls['Created Date'], format=\"%m/%d/%Y %I:%M:%S %p\")\n",
    "\n",
    "#An unlikely number of calls happened at 00:00:00,\n",
    "#probably didn't have the time stamp data (3512710/10012260)\n",
    "#Removing from data.\n",
    "\n",
    "odd_data = ((data_calls['Created Date'].dt.second == 0) &\n",
    "    (data_calls['Created Date'].dt.hour == 0) &\n",
    "    (data_calls['Created Date'].dt.minute == 0))\n",
    "\n",
    "clean_data = data_calls[ ~odd_data]\n",
    "\n",
    "hour = clean_data.groupby(clean_data['Created Date'].dt.hour)\n",
    "sorted_calls = hour.size().sort_values()\n",
    "print('Call Number Difference')\n",
    "print('{0:.10f}'.format(sorted_calls.iloc[-1]-sorted_calls.iloc[0]))\n",
    "\n",
    "#Find standard devation of time between calls\n",
    "\n",
    "time = clean_data['Created Date'].sort_values()\n",
    "time = (time-time.shift(1)).iloc[1:-1]\n",
    "print('standard deviation of time between calls')\n",
    "print('{0:.10f}'.format(np.std(time.dt.total_seconds())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Question 3  Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wearable sensors have become increasingly popular over the last few years with the success of smartphones, fitness trackers, and smart watches. Current generations of phones even contain special low power cores the constantly monitor movement. This allows them to act as pedometers for example with a negligible impact on battery life. Other use cases exist as well. For example, with android phones you can set your phone to stay unlocked until it detects that it hasn't moved for some time. The newest version on android even puts your phone in deep sleep to save power if the phone has not moved for a set period of time. This I feel is just the tip of the iceberg with it being possible to apply the data to different applications.\n",
    "\n",
    "I propose that we apply this data to advertising. For example, I show that just by using accelerometer data if it possible to differentiate between distracted states such as standing while talking, and walking while talking vs. standing, walking, and working at the computer. I argue that a person is more likely to interact with the advertisement if there is less competing stimulus from other people. This would allow a company to sell ads at a higher price if the persons phone lists them as not being distracted. \n",
    "\n",
    "To show the feasibly I use sensor data from UCI that only contains the raw x,y,z accelerometer data.  The data is labeled into 7 categories from 15 subjects.  (Working at Computer, Standing Up, Walking and Going Up/Down stairs, Standing, Walking, Going Up/Down Stairs, Walking while Talking, Standing while Talking.)\n",
    "\n",
    "Figure 1 ![Figure 1](https://raw.githubusercontent.com/damienrj/data_incubator/master/data.png) shows an example of the data where I calculate the magnitude of the acceleration vs. time.  The plot is color coded to indicate the labeled state.   I then preformed feature engineering to generate more features included low pass and high pass filtered versions of the data to highlight different behaviors.  I also used a rolling average to calculate the average acceleration within a one second window for the data.  The data was then split into training and testing sets.  Applying a random forest classifier with k-folds cross validation gave a score of 93% to the training data.  Using the test data, I also archived 93%.  Figure 2 ![Matrix](https://raw.githubusercontent.com/damienrj/data_incubator/master/matrix.png) is a confusion matrix generated showing that the model is predicting the different labels.\n",
    "\n",
    "This work clearly shows it is possible to differentiate between states,  and this is only using one accelerometer. Most smartphones have many more available sensors that would make it possible to archive even higher accuracy. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from __future__ import division\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from scipy import signal\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "#Sampling frequency of the accelerometer: 52 Hz \n",
    "labels={1: 'Working at Computer', 2:'Standing Up, Walking, and Going Up/Down Stairs',\n",
    "        3:'Standing', 4:'Walking', 5:'Going Up/Down Stairs', 6: 'Walking and Talking', 7:'Standing and Talking'}\n",
    "\n",
    "# Buterworth low pass filter\n",
    "N  = 2    # Filter order\n",
    "Wn = .1 # Cutoff frequency of 2.6 hz\n",
    "B, A = signal.butter(N, Wn)\n",
    "\n",
    "#High pass\n",
    "Wn = .9 # Cutoff frequency of 24 hz\n",
    "Bh, Ah = signal.butter(N, Wn, 'high')\n",
    "\n",
    "data=[]\n",
    "for a in range(1,16):\n",
    "    df = pd.read_csv('ActivityData/' + str(a) + '.csv' , header=None)\n",
    "    df.drop(0, axis=1, inplace=True)\n",
    "    df.columns = ['Accx', 'Accy', 'Accz', 'Label']\n",
    "    df['ID'] = a\n",
    "    df['Accx_filt'] = signal.filtfilt(B,A, df.Accx)\n",
    "    df['Accy_filt'] = signal.filtfilt(B,A, df.Accy)\n",
    "    df['Accz_filt'] = signal.filtfilt(B,A, df.Accz)\n",
    "    df['Accx_filt_h'] = signal.filtfilt(Bh,Ah, df.Accx)\n",
    "    df['Accy_filt_h'] = signal.filtfilt(Bh,Ah, df.Accy)\n",
    "    df['Accz_filt_h'] = signal.filtfilt(Bh,Ah, df.Accz)\n",
    "    df['Mean_x'] = pd.rolling_mean(df.Accx, 52)\n",
    "    df['Mean_y'] = pd.rolling_mean(df.Accy, 52)\n",
    "    df['Mean_z'] = pd.rolling_mean(df.Accz, 52)\n",
    "    if len(data)==0:\n",
    "        data = df\n",
    "    else:\n",
    "        data = pd.concat([data, df])\n",
    "        \n",
    "    \n",
    "data = data[~(data.Label==0)]\n",
    "data['Mag']= np.sqrt(data.Accx**2 + data.Accy**2 + data.Accz**2)\n",
    "\n",
    "#Remove edges of data where there is no rolling averages (~50 rows per subject)\n",
    "data=data[~data.Mean_x.isnull()]\n",
    "\n",
    "features = ['Mag', 'Accx', 'Accy', 'Accz', 'ID', 'Accx_filt',\n",
    "            'Accy_filt', 'Accz_filt', 'Accx_filt_h', 'Accy_filt_h',\n",
    "            'Accz_filt_h', 'Mean_x', 'Mean_y', 'Mean_z']\n",
    "\n",
    "#Split into training and testing data\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(data[features], data['Label'])\n",
    "\n",
    "#Simple K-Fold cross validation. 10 folds.\n",
    "cv = KFold(len(features_train), n_folds=10, indices=False)\n",
    "\n",
    "#iterate through the training and test cross validation segments and\n",
    "#run the classifier on each one, aggregating the results into a list\n",
    "results = []\n",
    "for traincv, testcv in cv:\n",
    "    rf.fit(features_train[traincv], labels_train[traincv])\n",
    "    results.append(rf.score(features_train[testcv], labels_train[testcv]))\n",
    "    \n",
    "    \n",
    "print('Mean score ' + str(np.mean(results)))\n",
    "\n",
    "#Train model on whole training set\n",
    "rf = RandomForestClassifier(n_estimators=20, n_jobs=-1, verbose=1, min_samples_leaf=3, oob_score=True)\n",
    "rf.fit(features_train, labels_train)\n",
    "\n",
    "print('Test score ' + str(rf.score(features_test,labels_test)))\n",
    "#Generate confusion_matrix\n",
    "con_matrix = confusion_matrix(labels_test, rf.predict(features_test))\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)\n",
    "\n",
    "\n",
    "%matplotlib \n",
    "\n",
    "plt.imshow(cm_normalized, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.colorbar()\n",
    "plt.xticks([0,1,2,3,4,5,6], [1,2,3,4,5,6,7])\n",
    "plt.yticks([0,1,2,3,4,5,6], [1,2,3,4,5,6,7])\n",
    "plt.grid(False)\n",
    "plt.savefig(\"matrix.png\")\n",
    "\n",
    "#Make plot for user 12\n",
    "user = data[data.ID==12]\n",
    "user.Mag-=np.min(user.Mag)\n",
    "user.Mag /= np.max(user.Mag)\n",
    "legend_text=[]\n",
    "\n",
    "t = np.arange(0, len(user.Label))/52\n",
    "sns.set_palette(sns.color_palette(\"Set2\", 8))\n",
    "for a in range(1,8):\n",
    "    plt.plot(t[np.array(user.Label==a)], user.Mag[user.Label==a], linewidth = 1)\n",
    "    legend_text.append(labels[a])\n",
    "\n",
    "plt.legend(legend_text,'best')\n",
    "plt.xlabel('Time(s)')\n",
    "plt.ylabel('Acceleration Magnitude (normalized)')\n",
    "plt.title('Subject 12 Data')\n",
    "plt.xlim(xmax=max(t))\n",
    "plt.savefig(\"data.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: MacOSX\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
